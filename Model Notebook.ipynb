{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import itertools\n",
    "import json\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('syn_dasta.csv')\n",
    "\n",
    "# LabelEncoder object: le\n",
    "le = LabelEncoder()\n",
    "\n",
    "df['proxy_species'] = pd.DataFrame(le.fit_transform(df['species']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['African elephant  ' 'African giant pouched rat' 'Arctic Fox  '\n",
      " 'Asian elephant  ' 'Baboon   ' 'Big brown bat ' 'Brazilian tapir  '\n",
      " 'Cat   ' 'Chimpanzee   ' 'Chinchilla   ']\n"
     ]
    }
   ],
   "source": [
    "# Create OneHotEncoder: ohe\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "# df_encoded\n",
    "df_encoded = pd.DataFrame(ohe.fit_transform(df['proxy_species'].values.reshape(-1, 1)))\n",
    "\n",
    "# Renaming columns\n",
    "df_encoded.columns = le.classes_\n",
    "\n",
    "print le.classes_\n",
    "\n",
    "# Joining df_encoded to df\n",
    "df = df.join(df_encoded)\n",
    "\n",
    "# print df_encoded\n",
    "\n",
    "# Dropping proxy_species and species\n",
    "df = df.drop(['species', 'proxy_species'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoder_list = zip(range(len(le.classes_)), le.classes_)\n",
    "# data = json.dumps({key: value for (key, value) in encoder_list})\n",
    "# with open(\"encoder.json\",\"w\") as f:\n",
    "#   f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age = 2.1\n",
    "# species = 'African giant pouched rat'\n",
    "\n",
    "# with open(\"encoder.json\", \"r\") as f:\n",
    "#     data = json.loads(f.read())\n",
    "    \n",
    "# cols = ['age']\n",
    "\n",
    "# colvals = [age]\n",
    "\n",
    "# for key in data:\n",
    "#     cols.append(str(data[key]))\n",
    "#     if data[key] == species:\n",
    "#         colvals.append(1)\n",
    "#     else:\n",
    "#         colvals.append(0)\n",
    "        \n",
    "# if species not in cols:\n",
    "#     return 'unknown species'\n",
    "\n",
    "# d = pd.DataFrame(columns=cols)\n",
    "\n",
    "# d.loc[0] = colvals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "# Separating features and target variable\n",
    "x, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "# Splitting into train and test ~ Hide\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=111)\n",
    "\n",
    "# Creating DMatrix\n",
    "df_dm = xgb.DMatrix(data=x, label=y)\n",
    "# df_dm = xgb.DMatrix(data=x_train, label=y_train)\n",
    "# df_dm_test = xgb.DMatrix(data=x_test)\n",
    "\n",
    "# parameter dictionary: params\n",
    "params = {\"objective\":\"reg:linear\"}\n",
    "\n",
    "# Create list of max_depth values\n",
    "eta_vals = [0.001, 0.01, 0.1]\n",
    "reg_params = [1, 10]\n",
    "max_depths = [1, 2, 5]\n",
    "subsamples = [0.3, 0.6, 0.9]\n",
    "\n",
    "list_of_params = [eta_vals, reg_params, max_depths, subsamples]\n",
    "params_vary = list(itertools.product(*list_of_params))\n",
    "\n",
    "print len(params_vary)\n",
    "\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary params\n",
    "for curr_val in params_vary:\n",
    "\n",
    "    params[\"eta\"] = curr_val[0]\n",
    "    params[\"lambda\"] = curr_val[1]\n",
    "    params[\"max_depth\"] = curr_val[2]\n",
    "    params[\"subsample\"] = curr_val[3]\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = xgb.cv(dtrain=df_dm, params=params, nfold=10, num_boost_round=100, early_stopping_rounds=25, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "comb = pd.DataFrame(list(zip(params_vary, best_rmse)),columns=[\"params\",\"best_rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(eta, lam, max_depth, subsample) = comb.loc[comb['best_rmse'].idxmin()]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\"objective\":\"reg:linear\", \"eta\": eta, \"lambda\": lam, \"max_depth\": max_depth, \"subsample\": subsample}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model: xg_reg\n",
    "xg_reg = xgb.train(params=params, dtrain=df_dm, num_boost_round=100)\n",
    "\n",
    "# Save the model\n",
    "xg_reg.save_model('trained.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load model\n",
    "# bst = xgb.Booster()  # init model\n",
    "# bst.load_model('trained.model')  # load data\n",
    "\n",
    "# # Predict the labels of the test set: preds\n",
    "# preds = bst.predict(df_dm_test)\n",
    "\n",
    "# # Compute and print the RMSE\n",
    "# rmse = np.sqrt(mean_squared_error(y_test,preds))\n",
    "# print(\"RMSE: %f\" % (rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
